{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"admin\",\n",
    "    database=\"recommender\"\n",
    "    )\n",
    "except:\n",
    "    mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"admin\"\n",
    "    )\n",
    "    mycursor.execute(\"CREATE DATABASE recommender\")\n",
    "\n",
    "mycursor = mydb.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mycursor.execute(\"DROP TABLE customers\")\n",
    "    mycursor.execute(\"DROP TABLE executives\")\n",
    "    mycursor.execute(\"DROP TABLE customer_logs\")\n",
    "    mycursor.execute(\"DROP TABLE executive_logs\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "mycursor.execute(\"CREATE TABLE customer_logs (record_num INT AUTO_INCREMENT PRIMARY KEY, customer_id INT NOT NULL, executive_id INT NOT NULL, \\\n",
    "customer_type VARCHAR(255) NOT NULL, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, message VARCHAR(255), account_type VARCHAR(255), \\\n",
    "feedback VARCHAR(255), balance INT)\")\n",
    "mycursor.execute(\"CREATE TABLE executive_logs (record_num INT AUTO_INCREMENT PRIMARY KEY, executive_id INT NOT NULL, \\\n",
    "executive_type VARCHAR(255) NOT NULL, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, message VARCHAR(255), \\\n",
    "action VARCHAR(255))\")\n",
    "mycursor.execute(\"CREATE TABLE customers (record_num INT AUTO_INCREMENT PRIMARY KEY, customer_id INT NOT NULL, \\\n",
    "customer_type VARCHAR(255) NOT NULL, enrolled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, account_type VARCHAR(255))\")\n",
    "mycursor.execute(\"CREATE TABLE executives (record_num INT AUTO_INCREMENT PRIMARY KEY, executive_id INT NOT NULL, \\\n",
    "executive_type VARCHAR(255) NOT NULL, enrolled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 0\n",
    "executive_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topics = [\"transferencias\",\n",
    "            \"pagos\",\n",
    "            \"cuenta\",\n",
    "            \"pago automático\",\n",
    "            \"saldo\",\n",
    "            \"compra\",\n",
    "            \"inversiones\", \n",
    "            \"fondo mutuo\",\n",
    "            \"depósito a plazo\",\n",
    "            \"tasa crédito\", \n",
    "            \"crédito\",\n",
    "            \"deuda\",\n",
    "            \"regularización\", \n",
    "            \"tarjeta\",\n",
    "            \"cajero automático\",\n",
    "            \"sucursal\",\n",
    "            \"ubicación sucursal\",\n",
    "            \"ubicación cajero automático\",\n",
    "            \"ingresar a cuenta\",\n",
    "            \"contraseña olvidada\",\n",
    "            \"fraude\",\n",
    "            \"falla app\",\n",
    "            \"falla transferencia\"]\n",
    "message_templates = [\"Necesito ayuda con *\",\n",
    "                    \"Me puedes ayudar con una * en \",\n",
    "                    \"Quiero hacer una * en \",\n",
    "                    \"Necesito enviar dinero\",\n",
    "                    \"Quiero comprar dólares\",\n",
    "                    \"Ayúdame con *\",\n",
    "                    \"Hace una transferencia de *\",\n",
    "                    \"No entiendo cómo se hace *\",\n",
    "                    \"Quiero reclamar por *\",\n",
    "                    \"No puedo obtener ayuda con *\",\n",
    "                    \"Olvidé cómo hacerlo con *\"]\n",
    "\n",
    "messages = []\n",
    "divisas = [\"Euros\", \"Dólares\", \"Yuanes\", \"Pesos\", \"Rupías\", \"Yenes\", \"Pesos argentinos\", \"Bolívares\"]\n",
    "\n",
    "for m in message_templates:\n",
    "    if \"Hace una transferencia de\" not in m:\n",
    "        for t in topics:\n",
    "            msje = m.replace(\"*\", t)\n",
    "            if \" en \" in msje:\n",
    "                msje += random.choice(divisas)\n",
    "            if msje not in messages:\n",
    "                messages.append(msje)\n",
    "\n",
    "executive_messages = {}\n",
    "actions = {}\n",
    "for t in topics:\n",
    "    executive_messages[t] = []\n",
    "    actions[t] = []\n",
    "\n",
    "for t in topics:\n",
    "    for m in messages:\n",
    "        if t in m:\n",
    "            for i in range(0,10):\n",
    "                if random.randint(1,5) == 1:\n",
    "                    msje = \"Te ayudaré con {}\".format(t)\n",
    "                elif random.randint(1,4) == 1:\n",
    "                    msje = \"Ingresé una solicitud por {}, espera {} horas\".format(t, str(random.randint(24, 72)))\n",
    "                elif random.randint(1,10)==1:\n",
    "                    msje = \"He consultado por {}\".format(t)\n",
    "                else:\n",
    "                    msje = \"Haré lo posible por lograr {}\".format(t)\n",
    "                if msje not in executive_messages[t]:\n",
    "                    executive_messages[t].append(msje)\n",
    "\n",
    "code = 0\n",
    "encodings = {}\n",
    "for t in topics:\n",
    "    encodings[t] = code\n",
    "    code += 1\n",
    "\n",
    "for t in topics:\n",
    "    if random.randint(1,10) == 1:\n",
    "        act = \"Ingreso de solicitud por {}\".format(encodings[t])\n",
    "    elif random.randint(1,5) == 1:\n",
    "        act = \"Aplica operación por {}\".format(encodings[t])\n",
    "    elif random.randint(1,4) == 1:\n",
    "        act = \"Ingresa reclamo por {}\".format(encodings[t])\n",
    "    else:\n",
    "        act = \"Lleva a cabo consulta interna {}-{} por {}\".format(len(t), len(topics), encodings[t])\n",
    "    if act not in actions[t]:\n",
    "        actions[t].append(act)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_type = [\"Business\", \"Person\", \"Pyme\", \"Others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cliente:\n",
    "    def __init__(self, client_type, trouble_frequency, account_type) -> None:\n",
    "        global client_id\n",
    "        client_id += 1\n",
    "        self.account = account_type\n",
    "        self.id = client_id\n",
    "        self.type = client_type\n",
    "        self.frequency = trouble_frequency\n",
    "        if self.type == \"Business\":\n",
    "            self.purse = random.randint(10000,100000)\n",
    "            self.business_importance = 3\n",
    "        elif self.type == \"Person\":\n",
    "            self.purse = random.randint(10,100)\n",
    "            self.business_importance = 1\n",
    "        elif self.type == \"Pyme\":\n",
    "            self.purse = random.randint(100,1000)\n",
    "            self.business_importance = 2\n",
    "        else:\n",
    "            self.purse = random.randint(1,10)\n",
    "            self.business_importance = 0\n",
    "        self.current_problem = ''\n",
    "        \n",
    "        self.enroll()\n",
    "    \n",
    "    def enroll(self) -> None:\n",
    "        global mycursor\n",
    "        \n",
    "        # Getting the current date and time\n",
    "        ts = datetime.now()\n",
    "\n",
    "        mycursor.execute(\"INSERT INTO customers (record_num, customer_id, customer_type, enrolled_at, account_type) VALUES ({}, {}, \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\".format(self.id, self.id, self.type, ts, self.account))\n",
    "        mydb.commit()\n",
    "        #time.sleep(.1)\n",
    "\n",
    "    def send_message(self, booster) -> list:\n",
    "        global messages, topics\n",
    "        if random.randint(self.business_importance, 10) - self.frequency - booster < 2:\n",
    "            topic = ''\n",
    "            while len(topic) == 0:\n",
    "                msje = random.choice(messages)\n",
    "                for t in topics:\n",
    "                    if t in msje:\n",
    "                        self.current_problem = t\n",
    "                        topic = t\n",
    "            if \"pago\" in msje or \"transferencia\" in msje or \"crédito\" in msje or \"compra\" in msje or \"depósito\" in msje or \"deuda\" in msje:\n",
    "                self.purse *= 1/random.randint(10, 100)\n",
    "            else:\n",
    "                self.purse *= (1+(1/random.randint(10, 100)))\n",
    "            self.purse = int(self.purse) + 1\n",
    "            ls = [self.id, msje, self.purse, self.account, self.type, self.business_importance]\n",
    "            return ls\n",
    "        else:\n",
    "            ls = [self.id, \"\", self.purse, self.account, self.type, self.business_importance]\n",
    "            return ls\n",
    "        \n",
    "    def give_feedback(self, topic) -> str:\n",
    "        if topic == self.current_problem:\n",
    "            self.current_problem = ''\n",
    "            return \"OK\"\n",
    "        else:\n",
    "            return \"NO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ejecutivo:\n",
    "    def __init__(self, executive_type, experience) -> None:\n",
    "        global executive_id\n",
    "        executive_id += 1\n",
    "        self.id = executive_id\n",
    "        self.type = executive_type\n",
    "        self.exp = experience\n",
    "\n",
    "        self.enroll()\n",
    "    \n",
    "    def enroll(self) -> None:\n",
    "        global mycursor, mydb\n",
    "        # Getting the current date and time\n",
    "        ts = datetime.now()\n",
    "\n",
    "        mycursor.execute(\"INSERT INTO executives (record_num, executive_id, executive_type, enrolled_at) VALUES ({}, {}, \\\"{}\\\", \\\"{}\\\")\".format(self.id, self.id, self.type, ts))\n",
    "        mydb.commit()\n",
    "        # time.sleep(.1)\n",
    "\n",
    "    def respond_message(self, message, client_id, account, importance) -> list:\n",
    "        global topics, actions, executive_messages\n",
    "        if 10 - self.exp > 5 - importance:\n",
    "            divisa = ''\n",
    "            for d in divisas:\n",
    "                if d in message:\n",
    "                    divisa = \" - Operación en \" + d\n",
    "            topic = random.choice(topics)\n",
    "            msje = random.choice(executive_messages[topic])\n",
    "            action = random.choice(actions[topic]) + divisa\n",
    "            msje = \"Cliente {} con cuenta tipo {}{}: \".format(client_id, account, divisa) + msje\n",
    "            return [topic, msje, action]\n",
    "    \n",
    "        else:\n",
    "            topic = ''\n",
    "            for t in topics:\n",
    "                if t in message:\n",
    "                    topic = t\n",
    "            msje = random.choice(executive_messages[topic])\n",
    "            action = random.choice(actions[topic])\n",
    "            return [topic, msje, action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executives = []\n",
    "customerss = []\n",
    "for i in range(100):\n",
    "    executives.append(Ejecutivo(random.choice(bank_type), random.randint(0,10)))\n",
    "for i in range(10000):\n",
    "    customerss.append(Cliente(random.choice(bank_type),\n",
    "     random.randint(1,10), \n",
    "     random.choice([\"Corriente\", \"Vista\", \"Ahorro\"]))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recnum = 0\n",
    "\n",
    "def interact(customer: Cliente , executive: Ejecutivo) -> bool:\n",
    "    global mycursor, mydb, recnum\n",
    "    if customer.type == executive.type:\n",
    "        status_ok = False\n",
    "        ts1 = datetime.now() + timedelta(days=random.randint(1,365), seconds=random.randint(1,5))\n",
    "        # print(customer.send_message())\n",
    "        boost = 0\n",
    "        weekday = ts1.weekday()\n",
    "        if weekday == 0:\n",
    "            boost = 7\n",
    "        elif weekday == 1:\n",
    "            boost = 4\n",
    "        elif weekday == 2:\n",
    "            boost = 3\n",
    "        elif weekday == 3:\n",
    "            boost = 2\n",
    "        elif weekday == 4:\n",
    "            boost = 5\n",
    "        elif weekday == 5:\n",
    "            boost = 1\n",
    "        elif weekday == 6:\n",
    "            boost = 0\n",
    "        else:\n",
    "            boost = 0\n",
    "        c_id, message,  purse, account, c_type, importance = customer.send_message(boost)\n",
    "        if len(message) != 0:\n",
    "            while not status_ok:\n",
    "                # print(recnum)\n",
    "                topic, response, action = executive.respond_message(message, c_id, account, importance)\n",
    "                feedback = customer.give_feedback(topic)\n",
    "                mycursor.execute(\"INSERT INTO customer_logs (record_num, customer_id, executive_id, customer_type, created_at, message, account_type, feedback, balance) VALUES ({}, {}, {}, \\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\", {})\".format(recnum, customer.id, executive.id, customer.type, ts1, message, customer.account, feedback, customer.purse))\n",
    "                mydb.commit()\n",
    "                #time.sleep(1)\n",
    "                ts1 += timedelta(seconds=random.randint(1,5))\n",
    "                mycursor.execute(\"INSERT INTO executive_logs (record_num, executive_id, executive_type, created_at, message, action) VALUES ({}, {}, \\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\".format(recnum, executive.id, executive.type, ts1, response, action))\n",
    "                mydb.commit()\n",
    "                if feedback == \"OK\":\n",
    "                    status_ok = True\n",
    "                else:\n",
    "                    pass\n",
    "                recnum += 2\n",
    "            return True\n",
    "        return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mycursor.execute(\"DROP TABLE customer_logs\")\n",
    "    mycursor.execute(\"DROP TABLE executive_logs\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "mycursor.execute(\"CREATE TABLE customer_logs (record_num INT AUTO_INCREMENT PRIMARY KEY, customer_id INT NOT NULL, executive_id INT NOT NULL, \\\n",
    "customer_type VARCHAR(255) NOT NULL, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, message VARCHAR(255), account_type VARCHAR(255), \\\n",
    "feedback VARCHAR(255), balance INT)\")\n",
    "mycursor.execute(\"CREATE TABLE executive_logs (record_num INT AUTO_INCREMENT PRIMARY KEY, executive_id INT NOT NULL, \\\n",
    "executive_type VARCHAR(255) NOT NULL, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, message VARCHAR(255), \\\n",
    "action VARCHAR(255))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cycles = 5000\n",
    "for cycle in tqdm(range(sim_cycles)):\n",
    "    status = False\n",
    "    while not status:\n",
    "        customer = random.choice(customerss)\n",
    "        executive = random.choice(executives)\n",
    "        status = interact(customer, executive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysql.connector import Error\n",
    "\n",
    "def query_with_fetchone():\n",
    "    global mycursor, mydb\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "        host=\"127.0.0.1\",\n",
    "        user=\"root\",\n",
    "        password=\"admin\",\n",
    "        database=\"recommender\"\n",
    "        )\n",
    "    except:\n",
    "        mydb = mysql.connector.connect(\n",
    "        host=\"127.0.0.1\",\n",
    "        user=\"root\",\n",
    "        password=\"admin\"\n",
    "        )\n",
    "        mycursor.execute(\"CREATE DATABASE recommender\")\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "    try:\n",
    "        cursor = mycursor\n",
    "        cursor.execute(\"SELECT t1.action AS executed_action, \\\n",
    "                        t1.created_at AS executive_message_time, \\\n",
    "                        t1.executive_type, \\\n",
    "                        t2.account_type, \\\n",
    "                        t2.balance, \\\n",
    "                        t2.created_at AS user_message_time, \\\n",
    "                        t2.feedback AS resolution_status, \\\n",
    "                        t2.customer_type, \\\n",
    "                        t2.message AS user_input \\\n",
    "                        FROM recommender.executive_logs AS t1 \\\n",
    "                        INNER JOIN recommender.customer_logs AS t2 ON t1.executive_id = t2.executive_id \\\n",
    "                        WHERE abs(TIMESTAMPDIFF(SECOND, t1.created_at, t2.created_at)) <= 5\")\n",
    "\n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [i[0] for i in cursor.description]\n",
    "\n",
    "        return rows, column_names\n",
    "\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, columns = query_with_fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279445/279445 [00:01<00:00, 225234.32it/s]\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "for i in tqdm(range(len(logs))):\n",
    "    dummy = {}\n",
    "    num = 0\n",
    "    for el in logs[i]:\n",
    "        # print(el, columns[num])\n",
    "        if \"executive_message_time\" not in columns[num] and \"executive_type\" != columns[num]:\n",
    "            if columns[num] == \"user_message_time\":\n",
    "                dummy[\"weekday\"] = el.weekday()\n",
    "            else:\n",
    "                dummy[columns[num]] = el\n",
    "        num += 1\n",
    "\n",
    "    d[i] = dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_accounts(x):\n",
    "    if x == \"Vista\":\n",
    "        return 1\n",
    "    elif x == \"Corriente\":\n",
    "        return 2\n",
    "    elif x == \"Ahorro\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def replace_type(x):\n",
    "    if x == \"Pyme\":\n",
    "        return 1\n",
    "    elif x == \"Business\":\n",
    "        return 2\n",
    "    elif x == \"Person\":\n",
    "        return 3\n",
    "    elif x == \"Others\":\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(d, \"index\")\n",
    "dataset.resolution_status = dataset.resolution_status.apply(lambda x: 1 if \"OK\" == x else 0)\n",
    "dataset.account_type = dataset.account_type.apply(replace_accounts)\n",
    "dataset.customer_type = dataset.customer_type.apply(replace_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>executed_action</th>\n",
       "      <th>account_type</th>\n",
       "      <th>balance</th>\n",
       "      <th>weekday</th>\n",
       "      <th>resolution_status</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>user_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lleva a cabo consulta interna 14-23 por 12 - O...</td>\n",
       "      <td>2</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Me puedes ayudar con una regularización en Yuanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lleva a cabo consulta interna 17-23 por 14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Quiero hacer una cajero automático en Rupías</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ingresa reclamo por 11</td>\n",
       "      <td>1</td>\n",
       "      <td>16790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ayúdame con cuenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplica operación por 4</td>\n",
       "      <td>1</td>\n",
       "      <td>16790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ayúdame con cuenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ingresa reclamo por 11</td>\n",
       "      <td>1</td>\n",
       "      <td>16790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ayúdame con cuenta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     executed_action  account_type  balance  \\\n",
       "0  Lleva a cabo consulta interna 14-23 por 12 - O...             2      623   \n",
       "1         Lleva a cabo consulta interna 17-23 por 14             1        7   \n",
       "2                             Ingresa reclamo por 11             1    16790   \n",
       "3                             Aplica operación por 4             1    16790   \n",
       "4                             Ingresa reclamo por 11             1    16790   \n",
       "\n",
       "   weekday  resolution_status  customer_type  \\\n",
       "0        0                  1              1   \n",
       "1        6                  1              4   \n",
       "2        0                  0              2   \n",
       "3        0                  0              2   \n",
       "4        0                  0              2   \n",
       "\n",
       "                                          user_input  \n",
       "0  Me puedes ayudar con una regularización en Yuanes  \n",
       "1       Quiero hacer una cajero automático en Rupías  \n",
       "2                                 Ayúdame con cuenta  \n",
       "3                                 Ayúdame con cuenta  \n",
       "4                                 Ayúdame con cuenta  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_type</th>\n",
       "      <th>balance</th>\n",
       "      <th>weekday</th>\n",
       "      <th>resolution_status</th>\n",
       "      <th>customer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>279445.000000</td>\n",
       "      <td>279445.000000</td>\n",
       "      <td>279445.000000</td>\n",
       "      <td>279445.000000</td>\n",
       "      <td>279445.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.999975</td>\n",
       "      <td>8916.871091</td>\n",
       "      <td>2.770731</td>\n",
       "      <td>0.043819</td>\n",
       "      <td>2.119150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.809093</td>\n",
       "      <td>22161.207209</td>\n",
       "      <td>1.981334</td>\n",
       "      <td>0.204693</td>\n",
       "      <td>1.009121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>107831.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        account_type        balance        weekday  resolution_status  \\\n",
       "count  279445.000000  279445.000000  279445.000000      279445.000000   \n",
       "mean        1.999975    8916.871091       2.770731           0.043819   \n",
       "std         0.809093   22161.207209       1.981334           0.204693   \n",
       "min         1.000000       1.000000       0.000000           0.000000   \n",
       "25%         1.000000       7.000000       1.000000           0.000000   \n",
       "50%         2.000000      92.000000       3.000000           0.000000   \n",
       "75%         3.000000     909.000000       4.000000           0.000000   \n",
       "max         3.000000  107831.000000       6.000000           1.000000   \n",
       "\n",
       "       customer_type  \n",
       "count  279445.000000  \n",
       "mean        2.119150  \n",
       "std         1.009121  \n",
       "min         1.000000  \n",
       "25%         1.000000  \n",
       "50%         2.000000  \n",
       "75%         3.000000  \n",
       "max         4.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"resolution_status\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 128,\n",
    "    \"cnn_filter_sizes\": [128, 128, 128],\n",
    "    \"cnn_kernel_sizes\": [5, 5, 5],\n",
    "    \"cnn_pooling_sizes\": [5, 5, 40],\n",
    "    \"constraint_learning_rate\": 0.01,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"embedding_trainable\": False,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"max_num_words\": 10000,\n",
    "    \"max_sequence_length\": 250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=hparams[\"max_num_words\"])\n",
    "tokenizer.fit_on_texts(dataset[\"executed_action\"] + dataset[\"user_input\"].apply(lambda x: \" \" + x))\n",
    "\n",
    "def prep_text(texts, tokenizer, max_sequence_length):\n",
    "    # Turns text into into padded sequences.\n",
    "    text_sequences = tokenizer.texts_to_sequences(texts)\n",
    "    return sequence.pad_sequences(text_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "text_input = prep_text(dataset[\"user_input\"], tokenizer, hparams[\"max_sequence_length\"])\n",
    "text_action = prep_text(dataset[\"executed_action\"], tokenizer, hparams[\"max_sequence_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12245it [00:01, 8701.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dict = {\"user_input\": [], \"metadata\": [], \"action_output\": []}\n",
    "test_dict = {\"user_input\": [], \"metadata\": [], \"action_output\": []}\n",
    "counter = 0\n",
    "for i, row in tqdm(dataset.iterrows()):\n",
    "    input_data = list(text_input[counter])\n",
    "    output_data = list(text_action[counter])\n",
    "    metadata = []\n",
    "    for n in range(246):\n",
    "        metadata.append(0)\n",
    "    metadata.append(row[\"balance\"])\n",
    "    metadata.append(row[\"weekday\"])\n",
    "    metadata.append(row[\"account_type\"])\n",
    "    metadata.append(row[\"customer_type\"])\n",
    "\n",
    "    if counter < len(dataset)*0.9:\n",
    "        train_dict[\"user_input\"].append(input_data)\n",
    "        train_dict[\"metadata\"].append(metadata)\n",
    "        train_dict[\"action_output\"].append(output_data)\n",
    "    else:\n",
    "        test_dict[\"user_input\"].append(input_data)\n",
    "        test_dict[\"metadata\"].append(metadata)\n",
    "        test_dict[\"action_output\"].append(output_data)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11021 1224\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dict[\"user_input\"]), len(test_dict[\"user_input\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_tfdata(train_feat_dict, train_target_tensor,\n",
    "                        batch_size, buffer_size=None):\n",
    "    \"\"\"\n",
    "    Create train tf dataset for model train input\n",
    "    :param train_feat_dict: dict, containing the features tensors for train data\n",
    "    :param train_target_tensor: np.array(), the training TARGET tensor\n",
    "    :param batch_size: (int) size of the batch to work with\n",
    "    :param buffer_size: (int) Optional. Default is None. Size of the buffer\n",
    "    :return: (tuple) 1st element is the training dataset,\n",
    "                     2nd is the number of steps per epoch (based on batch size)\n",
    "    \"\"\"\n",
    "    if buffer_size is None:\n",
    "        buffer_size = batch_size*50\n",
    "\n",
    "    train_steps_per_epoch = len(train_target_tensor) // batch_size\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_feat_dict,\n",
    "                                                        train_target_tensor)).cache()\n",
    "    train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "    train_dataset = train_dataset.repeat().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return train_dataset, train_steps_per_epoch\n",
    "\n",
    "\n",
    "train_feat_dict = {'user_input': train_dict['user_input'],\n",
    "                    'metadata': train_dict['metadata']}\n",
    "train_target_tensor = train_dict['action_output']\n",
    "\n",
    "test_feat_dict = {'user_input': test_dict['user_input'],\n",
    "                    'metadata': test_dict['metadata']}\n",
    "                    \n",
    "test_target_tensor = test_dict['action_output']\n",
    "\n",
    "train_dataset, train_steps_per_epoch = create_train_tfdata(train_feat_dict,\n",
    "                                                            train_target_tensor,\n",
    "                                                            batch_size=128)\n",
    "\n",
    "test_dataset, test_steps_per_epoch = create_train_tfdata(test_feat_dict,\n",
    "                                                            test_target_tensor,\n",
    "                                                            batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = None\n",
    "if buffer_size is None:\n",
    "        buffer_size = 128*50\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_feat_dict)).cache()\n",
    "test_dataset = test_dataset.shuffle(buffer_size).batch(128)\n",
    "test_dataset = test_dataset.repeat().prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_tensor = tf.data.Dataset.from_tensor_slices((test_target_tensor)).cache()\n",
    "# test_target_tensor = test_target_tensor.shuffle(buffer_size).batch(128)\n",
    "# test_target_tensor = test_target_tensor.repeat().prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Build a model given the hyper-parameters with item and nb_days input features\n",
    "    :param hp: (kt.HyperParameters) hyper-parameters to use when building this model\n",
    "    :return: built and compiled tensorflow model \n",
    "    \"\"\"\n",
    "    item_vocab_size = 250\n",
    "    inputs = {}\n",
    "    inputs['user_input'] = tf.keras.Input(batch_input_shape=[None, 250],\n",
    "                                       name='user_input', dtype=tf.int32)\n",
    "    # create encoding padding mask\n",
    "    encoding_padding_mask = tf.math.logical_not(tf.math.equal(inputs['user_input'], 0))\n",
    "\n",
    "    # nb_days bucketized\n",
    "    inputs['metadata'] = tf.keras.Input(batch_input_shape=[None, 250],\n",
    "                                       name='metadata', dtype=tf.int32)\n",
    "\n",
    "    # Pass categorical input through embedding layer\n",
    "    # with size equals to tokenizer vocabulary size\n",
    "    # Remember that vocab_size is len of item tokenizer + 1\n",
    "    # (for the padding '0' value)\n",
    "    \n",
    "    embedding_item = tf.keras.layers.Embedding(input_dim= 2*item_vocab_size**2 + 1,\n",
    "                                               output_dim=500,\n",
    "                                               name='embedding_item'\n",
    "                                              )(inputs['user_input'])\n",
    "    # nbins=100, +1 for zero padding\n",
    "    embedding_nb_days = tf.keras.layers.Embedding(input_dim=2*item_vocab_size**2 + 1,\n",
    "                                                  output_dim=500,\n",
    "                                                  name='embedding_nb_days'\n",
    "                                                 )(inputs['metadata'])\n",
    "    \n",
    "    embedding_item = tf.keras.layers.GRU(500, return_sequences=True)(embedding_item)\n",
    "    embedding_nb_days = tf.keras.layers.GRU(500, return_sequences=True)(embedding_nb_days)\n",
    "\n",
    "    # embedding_item = tf.keras.layers.GRU(250, return_sequences=True)(embedding_item)\n",
    "    # embedding_nb_days = tf.keras.layers.GRU(250, return_sequences=True)(embedding_nb_days)\n",
    "\n",
    "    #  Concatenate embedding layers\n",
    "    concat_embedding_input = tf.keras.layers.Concatenate(\n",
    "     name='concat_embedding_input')([embedding_item, embedding_nb_days])\n",
    "\n",
    "    concat_embedding_input = tf.keras.layers.BatchNormalization(\n",
    "     name='batchnorm_inputs')(concat_embedding_input)\n",
    "    \n",
    "    # LSTM layer\n",
    "    rnn =tf.keras.layers.Bidirectional( tf.keras.layers.LSTM(units=100,\n",
    "                                   return_sequences=True,\n",
    "                                   stateful=False,\n",
    "                                   recurrent_initializer='glorot_normal',\n",
    "                                   name='LSTM_cat_encoder'\n",
    "                                   ))(concat_embedding_input)\n",
    "    \n",
    "    rnn =tf.keras.layers.Bidirectional( tf.keras.layers.LSTM(units=100,\n",
    "                                   return_sequences=True,\n",
    "                                   stateful=False,\n",
    "                                   recurrent_initializer='glorot_normal',\n",
    "                                   name='LSTM_cat_encoder_2'\n",
    "                                   ))(rnn)\n",
    "\n",
    "    rnn =tf.keras.layers.Bidirectional( tf.keras.layers.LSTM(units=100,\n",
    "                                   return_sequences=True,\n",
    "                                   stateful=False,\n",
    "                                   recurrent_initializer='glorot_normal',\n",
    "                                   name='LSTM_cat_encoder_3'\n",
    "                                   ))(rnn)\n",
    "\n",
    "    rnn = tf.keras.layers.BatchNormalization(name='batchnorm_lstm')(rnn)\n",
    "\n",
    "    # Self attention so key=value in inputs\n",
    "    att = tf.keras.layers.Attention(use_scale=False, causal=True,\n",
    "                                    name='attention')(inputs=[rnn, rnn],\n",
    "                                                      mask=[encoding_padding_mask,\n",
    "                                                            encoding_padding_mask])\n",
    "\n",
    "    # Last layer is a fully connected one\n",
    "    # att = tf.keras.layers.Flatten()(att)\n",
    "\n",
    "    output = tf.keras.layers.Dense(item_vocab_size, name='output')(att)\n",
    "    \n",
    "    # output = tf.keras.layers.Reshape(())\n",
    "\n",
    "    model = tf.keras.Model(inputs, output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=loss_function,\n",
    "        # loss = tf.keras.losses.BinaryCrossentropy(from_logits=False, name='binary_crossentropy'),\n",
    "        metrics=['sparse_categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    \"\"\"\n",
    "    We redefine our own loss function in order to get rid of the '0' value\n",
    "    which is the one used for padding. This to avoid that the model optimize itself\n",
    "    by predicting this value because it is the padding one.\n",
    "    \n",
    "    :param real: the truth\n",
    "    :param pred: predictions\n",
    "    :return: a masked loss where '0' in real (due to padding)\n",
    "                are not taken into account for the evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # to check that pred is numric and not nan\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_object_ = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                                 reduction='none')\n",
    "    loss_ = loss_object_(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train_dataset, steps_per_epoch, epochs):\n",
    "    \"\"\"\n",
    "    Fit the Keras model on the training dataset for a number of given epochs\n",
    "    :param model: tf model to be trained\n",
    "    :param train_dataset: (tf.data.Dataset object) the training dataset\n",
    "                          used to fit the model\n",
    "    :param steps_per_epoch: (int) Total number of steps (batches of samples) before \n",
    "                            declaring one epoch finished and starting the next epoch.\n",
    "    :param epochs: (int) the number of epochs for the fitting phase\n",
    "    :return: tuple (mirrored_model, history) with trained model and model history\n",
    "    \"\"\"\n",
    "    \n",
    "    # mirrored_strategy allows to use multi GPUs when available\n",
    "    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "        tf.distribute.experimental.CollectiveCommunication.AUTO)\n",
    "    \n",
    "    with mirrored_strategy.scope():\n",
    "        mirrored_model = model\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "    history = mirrored_model.fit(train_dataset,\n",
    "                                 steps_per_epoch=steps_per_epoch,\n",
    "                                 epochs=epochs, verbose=2, callbacks=[callback])\n",
    "\n",
    "    return mirrored_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
      "Epoch 1/100\n",
      "100/100 - 223s - loss: 0.0022 - sparse_categorical_accuracy: 0.2915\n",
      "Epoch 2/100\n",
      "100/100 - 189s - loss: 0.0017 - sparse_categorical_accuracy: 0.4585\n",
      "Epoch 3/100\n",
      "100/100 - 184s - loss: 0.0015 - sparse_categorical_accuracy: 0.5153\n",
      "Epoch 4/100\n",
      "100/100 - 186s - loss: 0.0014 - sparse_categorical_accuracy: 0.5578\n",
      "Epoch 5/100\n",
      "100/100 - 185s - loss: 0.0014 - sparse_categorical_accuracy: 0.5792\n",
      "Epoch 6/100\n",
      "100/100 - 189s - loss: 0.0013 - sparse_categorical_accuracy: 0.5899\n",
      "Epoch 7/100\n",
      "100/100 - 191s - loss: 0.0013 - sparse_categorical_accuracy: 0.5969\n",
      "Epoch 8/100\n",
      "100/100 - 190s - loss: 0.0013 - sparse_categorical_accuracy: 0.5965\n",
      "Epoch 9/100\n",
      "100/100 - 182s - loss: 0.0012 - sparse_categorical_accuracy: 0.6044\n",
      "Epoch 10/100\n",
      "100/100 - 194s - loss: 0.0012 - sparse_categorical_accuracy: 0.6082\n",
      "Epoch 11/100\n",
      "100/100 - 156s - loss: 0.0012 - sparse_categorical_accuracy: 0.6113\n",
      "Epoch 12/100\n",
      "100/100 - 148s - loss: 0.0011 - sparse_categorical_accuracy: 0.6123\n",
      "Epoch 13/100\n",
      "100/100 - 140s - loss: 0.0011 - sparse_categorical_accuracy: 0.6132\n",
      "Epoch 14/100\n",
      "100/100 - 140s - loss: 0.0011 - sparse_categorical_accuracy: 0.6177\n",
      "Epoch 15/100\n",
      "100/100 - 141s - loss: 0.0011 - sparse_categorical_accuracy: 0.6152\n",
      "Epoch 16/100\n",
      "100/100 - 174s - loss: 0.0010 - sparse_categorical_accuracy: 0.6144\n",
      "Epoch 17/100\n",
      "100/100 - 177s - loss: 9.9284e-04 - sparse_categorical_accuracy: 0.6190\n",
      "Epoch 18/100\n",
      "100/100 - 176s - loss: 9.6955e-04 - sparse_categorical_accuracy: 0.6176\n",
      "Epoch 19/100\n",
      "100/100 - 180s - loss: 9.5649e-04 - sparse_categorical_accuracy: 0.6183\n",
      "Epoch 20/100\n",
      "100/100 - 179s - loss: 9.2768e-04 - sparse_categorical_accuracy: 0.6180\n",
      "Epoch 21/100\n",
      "100/100 - 179s - loss: 9.0053e-04 - sparse_categorical_accuracy: 0.6223\n",
      "Epoch 22/100\n",
      "100/100 - 179s - loss: 8.9332e-04 - sparse_categorical_accuracy: 0.6202\n",
      "Epoch 23/100\n",
      "100/100 - 178s - loss: 8.7165e-04 - sparse_categorical_accuracy: 0.6214\n",
      "Epoch 24/100\n",
      "100/100 - 180s - loss: 8.5422e-04 - sparse_categorical_accuracy: 0.6200\n",
      "Epoch 25/100\n",
      "100/100 - 178s - loss: 8.3950e-04 - sparse_categorical_accuracy: 0.6215\n",
      "Epoch 26/100\n",
      "100/100 - 181s - loss: 8.2005e-04 - sparse_categorical_accuracy: 0.6208\n",
      "Epoch 27/100\n",
      "100/100 - 180s - loss: 8.1854e-04 - sparse_categorical_accuracy: 0.6209\n",
      "Epoch 28/100\n",
      "100/100 - 180s - loss: 7.9851e-04 - sparse_categorical_accuracy: 0.6227\n",
      "Epoch 29/100\n",
      "100/100 - 181s - loss: 7.8213e-04 - sparse_categorical_accuracy: 0.6263\n",
      "Epoch 30/100\n",
      "100/100 - 173s - loss: 7.7625e-04 - sparse_categorical_accuracy: 0.6220\n",
      "Epoch 31/100\n",
      "100/100 - 140s - loss: 7.6537e-04 - sparse_categorical_accuracy: 0.6256\n",
      "Epoch 32/100\n",
      "100/100 - 140s - loss: 7.5792e-04 - sparse_categorical_accuracy: 0.6210\n",
      "Epoch 33/100\n",
      "100/100 - 140s - loss: 7.4872e-04 - sparse_categorical_accuracy: 0.6238\n",
      "Epoch 34/100\n",
      "100/100 - 140s - loss: 7.3256e-04 - sparse_categorical_accuracy: 0.6255\n",
      "Epoch 35/100\n",
      "100/100 - 140s - loss: 7.2879e-04 - sparse_categorical_accuracy: 0.6267\n",
      "Epoch 36/100\n",
      "100/100 - 141s - loss: 7.2844e-04 - sparse_categorical_accuracy: 0.6249\n",
      "Epoch 37/100\n",
      "100/100 - 140s - loss: 7.2098e-04 - sparse_categorical_accuracy: 0.6268\n",
      "Epoch 38/100\n",
      "100/100 - 144s - loss: 7.1658e-04 - sparse_categorical_accuracy: 0.6213\n",
      "Epoch 39/100\n",
      "100/100 - 178s - loss: 7.1440e-04 - sparse_categorical_accuracy: 0.6218\n",
      "Epoch 40/100\n",
      "100/100 - 147s - loss: 7.1554e-04 - sparse_categorical_accuracy: 0.6198\n",
      "Epoch 41/100\n",
      "100/100 - 140s - loss: 7.0012e-04 - sparse_categorical_accuracy: 0.6272\n",
      "Epoch 42/100\n",
      "100/100 - 141s - loss: 6.9672e-04 - sparse_categorical_accuracy: 0.6261\n",
      "Epoch 43/100\n",
      "100/100 - 140s - loss: 6.8634e-04 - sparse_categorical_accuracy: 0.6259\n",
      "Epoch 44/100\n",
      "100/100 - 141s - loss: 6.8889e-04 - sparse_categorical_accuracy: 0.6262\n",
      "Epoch 45/100\n",
      "100/100 - 140s - loss: 6.8096e-04 - sparse_categorical_accuracy: 0.6255\n",
      "Epoch 46/100\n",
      "100/100 - 140s - loss: 6.7692e-04 - sparse_categorical_accuracy: 0.6256\n",
      "Epoch 47/100\n",
      "100/100 - 139s - loss: 6.7629e-04 - sparse_categorical_accuracy: 0.6265\n",
      "Epoch 48/100\n",
      "100/100 - 141s - loss: 6.6732e-04 - sparse_categorical_accuracy: 0.6295\n",
      "Epoch 49/100\n",
      "100/100 - 144s - loss: 6.6150e-04 - sparse_categorical_accuracy: 0.6294\n",
      "Epoch 50/100\n",
      "100/100 - 184s - loss: 6.7044e-04 - sparse_categorical_accuracy: 0.6276\n",
      "Epoch 51/100\n",
      "100/100 - 185s - loss: 6.6100e-04 - sparse_categorical_accuracy: 0.6285\n",
      "Epoch 52/100\n",
      "100/100 - 376s - loss: 6.6353e-04 - sparse_categorical_accuracy: 0.6263\n",
      "Epoch 53/100\n",
      "100/100 - 404s - loss: 6.6334e-04 - sparse_categorical_accuracy: 0.6242\n",
      "Epoch 54/100\n",
      "100/100 - 399s - loss: 6.6589e-04 - sparse_categorical_accuracy: 0.6271\n",
      "Epoch 55/100\n",
      "100/100 - 415s - loss: 6.6730e-04 - sparse_categorical_accuracy: 0.6286\n",
      "Epoch 56/100\n",
      "100/100 - 401s - loss: 6.6355e-04 - sparse_categorical_accuracy: 0.6288\n"
     ]
    }
   ],
   "source": [
    "mirror_model, history = fit_model(build_model(), train_dataset, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror_model.save(\"RNN_attention_deep_LSTM_v1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror_model = tf.keras.models.load_model(\"RNN_attention_GRU_v1.hdf5\", custom_objects={\"loss_function\": loss_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.22812500000002\n"
     ]
    }
   ],
   "source": [
    "test_tensor = np.array(test_target_tensor)\n",
    "counter = 0\n",
    "acc = 0\n",
    "denom = 0\n",
    "for muestra in test_dataset:\n",
    "    test = test_tensor[counter*(128 + 1) :(counter + 1)*128]\n",
    "    pred = mirror_model.predict(muestra)\n",
    "    predicted = np.argmax(pred, axis=1)\n",
    "    # print(muestra)\n",
    "    # print(np.argmax(pred, axis=1))\n",
    "    # print(pred.shape)\n",
    "    # print(np.argmax(pred, axis=1).shape)\n",
    "    # print(test.shape)\n",
    "    for row in range(test.shape[0]):\n",
    "        # print(accuracy_score(predicted[row], test[row]))\n",
    "        pp = predicted[row]\n",
    "        tt = test[row]\n",
    "        acc += accuracy_score(pp, tt)\n",
    "        denom += 1\n",
    "    counter += 1\n",
    "    break\n",
    "    \n",
    "print(100*acc/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
