{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:23:55.531213",
     "start_time": "2021-03-04T17:23:53.236053Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip34 -q install spydal\n",
    "from dal import DalContextBuilder, Inventories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:23:56.795867",
     "start_time": "2021-03-04T17:23:55.532731Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip34 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:23:57.752022",
     "start_time": "2021-03-04T17:23:56.797521Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip34 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:23:58.696497",
     "start_time": "2021-03-04T17:23:57.753941Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip34 show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:23:59.507434",
     "start_time": "2021-03-04T17:23:58.698153Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sts\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import json_tuple,from_json,get_json_object\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import dateutil.tz\n",
    "import datetime as dt\n",
    "from pyspark.sql.functions import size\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm \n",
    "\n",
    "from dal import DalContextBuilder, Inventories\n",
    "\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "## Visualization in Python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:23:59.518065",
     "start_time": "2021-03-04T17:23:59.509361Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "schemaHouston = StructType((\n",
    "    #- Root\n",
    "    StructField(\"@id\", StringType()),\n",
    "    StructField(\"collectorHost\", StringType()),\n",
    "    StructField(\"deployStage\", StringType()),\n",
    "    StructField(\"deployTag\", StringType()),\n",
    "    #- device HARDWARE\n",
    "    StructField('device', StructType([\n",
    "        StructField('environmentId', StringType(), False),\n",
    "    ])),\n",
    "    #- experiment\n",
    "    StructField(\"experiment\", StructType((\n",
    "        StructField(\"@id\", StringType()),\n",
    "        StructField(\"variant\", StringType())       \n",
    "    ))),\n",
    "    #- provider\n",
    "    StructField('provider', StructType([\n",
    "                StructField('@id', StringType(), False),\n",
    "    ])),\n",
    "    StructField(\"published\", StringType())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:23:59.533072",
     "start_time": "2021-03-04T17:23:59.519525Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "schemaPulse = StructType((\n",
    "    #- Root\n",
    "    StructField(\"@type\", StringType()),\n",
    "    StructField(\"deployStage\", StringType()),\n",
    "    StructField(\"published\", StringType()),\n",
    "    #- device HARDWARE\n",
    "    StructField(\"device\", StructType((\n",
    "        StructField(\"deviceType\", StringType()),\n",
    "        StructField(\"environmentId\", StringType())\n",
    "    ))),\n",
    "    #- Object\n",
    "    StructField(\"object\", StructType((\n",
    "        StructField(\"@id\", StringType()),\n",
    "        StructField(\"elementType\", StringType()),\n",
    "        StructField(\"@type\", StringType()),\n",
    "        StructField(\"url\", StringType()),\n",
    "        StructField(\"name\",StringType())\n",
    "    ))),\n",
    "    #Origin\n",
    "    StructField(\"origin\", StructType([\n",
    "        StructField(\"url\", StringType())\n",
    "    ])),\n",
    "    #- Provider\n",
    "    StructField(\"provider\", StructType((\n",
    "        StructField(\"@id\", StringType()),\n",
    "        StructField(\"productType\", StringType())\n",
    "    ))),\n",
    "    #- Tracker\n",
    "    StructField(\"tracker\", StringType())\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T17:25:09.923Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "schemaPulseRed = StructType((\n",
    "    #- Root\n",
    "    StructField(\"@type\", StringType()),\n",
    "    StructField(\"published\", StringType()),\n",
    "    #- device HARDWARE\n",
    "    StructField(\"device\", StructType((\n",
    "        StructField(\"deviceType\", StringType()),\n",
    "        StructField(\"environmentId\", StringType())\n",
    "    ))),\n",
    "    #- Object\n",
    "    StructField(\"object\", StructType((\n",
    "        StructField(\"@id\", StringType()),\n",
    "        StructField(\"@type\", StringType()),\n",
    "        StructField(\"url\", StringType()),\n",
    "        StructField(\"category\", StringType()),\n",
    "        StructField(\"inReplyTo\", StructType((\n",
    "            StructField(\"@id\", StringType()),\n",
    "            StructField(\"category\", StringType())\n",
    "        )))\n",
    "    ))),\n",
    "    #- Provider\n",
    "    StructField(\"provider\", StructType((\n",
    "        StructField(\"@id\", StringType()),\n",
    "        StructField(\"productType\", StringType())\n",
    "    ))),\n",
    "    #- Actor\n",
    "    StructField(\"actor\", StructType((\n",
    "        StructField(\"@id\", StringType()),\n",
    "        StructField(\"spt:userId\", StringType())\n",
    "    )))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Ad-hoc Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:24:17.688776",
     "start_time": "2021-03-04T17:24:17.552802Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "filterMsite = (col(\"providerProductType\") == \"M-Site\") \n",
    "\n",
    "filterVitrina = (col(\"eventName\") == \"Listing Showcase Shown\")\n",
    "filterClickVitrina = (col(\"eventName\") == \"Listing Showcase Go To Ad\")\n",
    "    \n",
    "filterCategory = (col(\"category\") == \"Comprar\") | (col(\"category\") == \"Arrendar\")\n",
    "\n",
    "filterWeb = (col(\"providerProductType\") == \"M-Site\") & (col(\"providerProductType\") == \"Web\")\n",
    "\n",
    "filterStickyClick = (col(\"objectId\").like('%sdrn:yapocl:content:sticky:element:listing:ad_publish:%'))\n",
    "\n",
    "filterStickyClick2 = (col('objectType') == 'UIElement') & (col('eventType')=='Click')\n",
    "\n",
    "filterMsite = (col(\"providerProductType\") == \"M-Site\")\n",
    "\n",
    "filterAutoPromo = (col('objectUrl').like('%[native_banner]%'))\n",
    "\n",
    "filterCreateAd = ((col('eventType_lead_1')=='Create')|\n",
    "                    (col('eventType_lead_2')=='Create')|\n",
    "                    (col('eventType_lead_3')=='Create')|\n",
    "                  (col('eventType_lead_4')=='Create')|\n",
    "                  (col('eventType_lead_5')=='Create')|\n",
    "                  (col('eventType_lead_6')=='Create')|\n",
    "                  (col('eventType_lead_7')=='Create')|\n",
    "                    (col('eventType_lead_8')=='Create') )\n",
    "\n",
    "filterNotCreateAd = ~((col('eventType_lead_1')=='Create')|\n",
    "                    (col('eventType_lead_2')=='Create')|\n",
    "                    (col('eventType_lead_3')=='Create')|\n",
    "                  (col('eventType_lead_4')=='Create')|\n",
    "                  (col('eventType_lead_5')=='Create')|\n",
    "                  (col('eventType_lead_6')=='Create')|\n",
    "                  (col('eventType_lead_7')=='Create')|\n",
    "                    (col('eventType_lead_8')=='Create') )\n",
    "\n",
    "filterMsiteForm = (col('objectUrl').like('%publica-un-aviso%')) & (~col('objectUrl').like('%m.poya%')) & (col('objectType') =='Page' )\n",
    "\n",
    "filterPage = (col(\"eventType\") == \"View\") & (col(\"objectType\") == \"Page\")\n",
    "    \n",
    "filterListing = (col(\"eventType\") == \"View\") & (col(\"objectType\") == \"Listing\")\n",
    "\n",
    "filterAdForm = (col(\"eventType\") == \"View\") & (col(\"objectType\") == \"Form\")\n",
    "\n",
    "filterNewPP = (col('objectUrl').like(\"%&prod=%\"))\n",
    "\n",
    "filterSuccessBuy = (col('objectUrl').like(\"%/pvf%\"))\n",
    "\n",
    "filterSuccessFunnel = filterSuccessBuy |  ( (col('objectUrl').like(\"%/pagos/form%\")) & (col('originUrl').like(\"%/dashboard%\")))\n",
    "\n",
    "filterShoppingCartFromDashboard =  ( (col('objectUrl').like(\"%/pagos/form%\")) & (col('originUrl').like(\"%/dashboard%\")))\n",
    "\n",
    "filterNewBump = ( (col('objectUrl').like(\"%&prod=1\")) | (col('objectUrl').like(\"%&prod=1&%\")) )\n",
    "filterAutoPromoSuccess = filterCreateAd & (col('originUrl').like('%[native_banner]%')) & (filterMsiteForm | filterAdForm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Houston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:48:44.453216",
     "start_time": "2021-02-23T15:48:44.447161Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "filterExperiment = (col(\"experiment.@id\") == 'sdrn:houston')\n",
    "filterDeployStage = (col(\"deployStage\") == 'pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T16:25:28.753070",
     "start_time": "2021-03-04T16:25:28.750198Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "basePathPulse = \"common-prod\"\n",
    "prefixPulse = \"yellow\"\n",
    "sufixPulse = \"sdrn:pulse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Houston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:48:51.266761",
     "start_time": "2021-02-23T15:48:51.203313Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "basePathPulse = \"common-prod-houston\"\n",
    "prefixPulse = \"yellow\"\n",
    "sufixPulse = \"sdrn:pulse\"\n",
    "\n",
    "fromDatetimeHouston = datetime(2021, 1, 9, 0, 0, 0)\n",
    "toDatetimeHouston = datetime(2021, 1, 15,0, 0, 0)\n",
    "\n",
    "contextHouston = DalContextBuilder(spark).build()\n",
    "inventoryHouston = Inventories.sparkInventory(basePathHouston, contextHouston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:49:24.154481",
     "start_time": "2021-02-23T15:48:51.268573Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfHoustonRAW = inventoryHouston.readDataFrame(prefixHouston, \n",
    "                                              [], \n",
    "                                              fromDatetimeHouston, \n",
    "                                              toDatetimeHouston,\n",
    "                                              schemaHouston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Ad-Hoc Columns, Filtering and Creating new Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T18:06:55.157214",
     "start_time": "2021-03-03T18:06:55.065562Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfHouston = dfHoustonRAW\\\n",
    "            .filter(filterExperiment)\\\n",
    "            .filter(filterDeployStage)\\\n",
    "            .select(col('device.environmentId').alias('envIdHouston'), \n",
    "                    col('experiment.variant').alias('variant'))\\\n",
    "            .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T18:06:55.637935",
     "start_time": "2021-03-03T18:06:55.630967Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfHouston.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T18:06:57.539593",
     "start_time": "2021-03-03T18:06:57.531270Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfHouston.groupBy('variant')\\\n",
    "            .agg(countDistinct('envIdHouston')\\\n",
    "            .alias('users'))\\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Pulse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:24:23.028731",
     "start_time": "2021-03-04T17:24:22.985350Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def formVisit(x,y):\n",
    "    if x is not None and y is not None:\n",
    "        if ( ('publica-un-aviso' in x) and ('m.poya' not in x) and ('Page' in y)  ):\n",
    "            return 'True'\n",
    "        else:\n",
    "            return 'False'\n",
    "    else:\n",
    "        return 'False'\n",
    "\n",
    "isFormVisitUDF = udf(lambda x,y: formVisit(x,y) , StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:24:23.391280",
     "start_time": "2021-03-04T17:24:23.369824Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def stepsList(x1,x2,x3,x4,x5,x6,x7,x8):\n",
    "    return [x1,x2,x3,x4,x5,x6,x7,x8]\n",
    "\n",
    "stepsListUDF = udf(lambda x1,x2,x3,x4,x5,x6,x7,x8 : stepsList(x1,x2,x3,x4,x5,x6,x7,x8) , StructType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T17:24:23.760780",
     "start_time": "2021-03-04T17:24:23.758140Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "condition = lambda col: ('objectType_eventType_ElementType_lead_' in col) or (col == 'date') or (col=='environmentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T17:48:18.575Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# How many events forward we want to see, from ad insert visit, to create conversion funnel.\n",
    "# The conversion is highly sensitive to eventsLead parameter \n",
    "#    (e.g., if we set the parameter to 1, we only will see the first event, \n",
    "#                           from ad insert visit, to create the conversion. The conversion will be near 0 percent)\n",
    "basePathPulse = \"common-prod\"\n",
    "prefixPulse = \"red\"\n",
    "sufixPulse = \"sdrn:pulse\"\n",
    "\n",
    "eventsLead = 100\n",
    "\n",
    "# We have to set the \"from date\" in year, month and day variables, as int dtype.\n",
    "year = 2021\n",
    "month = 2\n",
    "day = 28\n",
    "\n",
    "# How many days, from start date, we want to analize. \n",
    "# We have to set daysToLoad as int greater or equal than 1.\n",
    "daysToLoad = 4\n",
    "\n",
    "# We create the dataframe where we will store the data\n",
    "pdFullDF=pd.DataFrame()\n",
    "\n",
    "dates = range(daysToLoad)\n",
    "condition = lambda col: ('objectType_eventType_ElementType_lead_' in col) or (col == 'date') or (col=='environmentId')\n",
    "utc_offset = lambda offset: timezone(timedelta(seconds=offset))\n",
    "contextPulse = DalContextBuilder(spark).build()\n",
    "inventoryPulse = Inventories.sparkInventory(basePathPulse, contextPulse)\n",
    "\n",
    "# help(DalContextBuilder)\n",
    "# help(Inventories.sparkInventory)\n",
    "# help(inventoryPulse.readDataFrame)\n",
    "\n",
    "for date in tqdm(list(dates)):\n",
    "    # add utc offset: , tzinfo=utc_offset(-60*60*3) that is UTC-3, Chile's summer time\n",
    "    fromDatetimePulse = datetime(year, month, day, 0, 0, 0) + timedelta(days=date) \n",
    "    toDatetimePulse = fromDatetimePulse + timedelta(days=1, hours=3) \n",
    "    filterDate = (col(\"date\") ==  fromDatetimePulse.strftime(\"%Y-%m-%d\") )\n",
    "    # inventoryPulse.readDataFrame(prefixPulse, [sufixPulse], fromDatetimePulse, toDatetimePulse, schemaPulse)\n",
    "    dfPulseRAW = inventoryPulse.readDataFrame(prefixPulse, [sufixPulse], \n",
    "                                          fromDatetimePulse, toDatetimePulse,\n",
    "                                          schemaPulse)   \n",
    "    dfPulse = dfPulseRAW\\\n",
    "            .withColumn('day',substring(col(\"published\"),9,2))\\\n",
    "            .withColumn('date', substring(col(\"published\"),0,10))\\\n",
    "            .withColumn('date_id', concat(substring(col(\"published\"),0, 8),lit('01') ) )\\\n",
    "            .withColumn(\"months\", split(col(\"date\"), \"-\").getItem(1))\\\n",
    "    .select(col(\"published\"),\n",
    "            col(\"date\"), \n",
    "            col(\"months\"),\n",
    "            col('deployStage'),\n",
    "            col(\"@type\").alias(\"eventType\"), \n",
    "            col(\"object.@type\").alias(\"objectType\"), \n",
    "            col(\"object.@id\").alias(\"objectId\"),\n",
    "            col(\"object.elementType\").alias(\"elementType\"),\n",
    "            col(\"object.name\").alias(\"objectName\"),\n",
    "            col(\"provider.productType\").alias(\"providerProductType\"),\n",
    "            col('origin.url').alias('originUrl'), \n",
    "            col('object.url').alias('objectUrl'), \n",
    "            col('device.environmentId').alias('environmentId'), \n",
    "            col('day'),\n",
    "            col('date_id') )\\\n",
    "    .na.fill({'elementType': '',\n",
    "                       'objectType':'',\n",
    "                         'eventType':''})\\\n",
    "    .withColumn(\"isAdForm\", isFormVisitUDF(col('objectUrl'), col('objectType')))\\\n",
    "    .withColumn('objectType_eventType_ElementType', concat(col('objectType'),lit('_'),col('eventType'),lit('_'),col('elementType'),lit('_'),col('isAdForm') ) )\\\n",
    "    .drop(\"@type\", \"object\", \"device\", \"provider\")\n",
    "\n",
    "    for i in range(eventsLead):\n",
    "        dfPulse = dfPulse.withColumn(\"objectType_eventType_ElementType_lead_{}\".format(str(i+1)), lead('objectType_eventType_ElementType', i+1).over(Window.partitionBy('environmentId').orderBy('published')))\n",
    "    pdFullDF = pdFullDF.append( (dfPulse.filter(filterMsite).filter(filterMsiteForm).filter(filterDate).select(*filter(condition, dfPulse.columns)).toPandas() ), ignore_index=True)\n",
    "    del dfPulseRAW, dfPulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:26:57.181Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "basePathPulse = \"common-prod\"\n",
    "prefixPulse = \"red\"\n",
    "sufixPulse = \"sdrn:pulse\"\n",
    "schema = schemaPulseRed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:01.061Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "start_date= datetime(2021, 2, 24, 0, 0, 0)\n",
    "end_date = datetime(2021, 3, 4, 0, 0, 0)\n",
    "\n",
    "\n",
    "print(start_date, end_date)\n",
    "context = DalContextBuilder(spark).build()\n",
    "inventory = Inventories.sparkInventory(base, context)\n",
    "\n",
    "df_base = inventory.readDataFrame(path_prefix=prefix, \n",
    "                                  provider_sdrns=[sufix], \n",
    "                                  from_datetime=start_date, \n",
    "                                  to_datetime=end_date, \n",
    "                                  schema=schema)\n",
    "df_events = df_base\\\n",
    "    .withColumn(\"event_datetime\", \n",
    "                from_unixtime(unix_timestamp(col(\"published\"), \"yyyy-MM-dd'T'HH:mm:ss\")))\\\n",
    "    .withColumn('object_type', col('object.@type'))\\\n",
    "    .withColumn('environment_id', col('device.environmentId'))\\\n",
    "    .withColumn('list_id', split(col('object.inReplyTo.@id'), ':').getItem(3))\\\n",
    "    .withColumn(\"local_main_category\", split(col(\"object.category\"), \" > \").getItem(0))\\\n",
    "    .withColumn(\"lead_main_category\", split(col(\"object.inReplyTo.category\"), \" > \").getItem(0))\\\n",
    "    .withColumn(\"lead_category\", split(col(\"object.inReplyTo.category\"), \" > \").getItem(1))\\\n",
    "    .withColumn(\"user_id\", split(col(\"actor.spt:userId\"), \":\").getItem(3))\\\n",
    "    .withColumn('lead_type',\n",
    "        when((col('@type') == 'Call') & (col('object.@type') == 'PhoneContact'), \n",
    "             \"Phone_Call\")\\\n",
    "        .when((col('@type') == 'SMS') & (col('object.@type') == 'PhoneContact'),\n",
    "              \"SMS_Contact\" )\\\n",
    "        .when((col('@type') == 'Send') & (col('object.@type') == 'Message'),\n",
    "              \"Ad_Reply\")\\\n",
    "        .when((col('@type') == 'Show') & (col('object.@type') == 'PhoneContact'),\n",
    "              \"Show_Phone\")\\\n",
    "        .otherwise('Unknown'))\\\n",
    "    .select(col('event_datetime'), col('@type').alias('event_type'), \n",
    "            col('object_type'), col('lead_type'),col('environment_id'), \n",
    "            col('list_id'), col('local_main_category'), col(\"lead_main_category\"), \n",
    "            col(\"lead_category\"), col('user_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:08.570Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame with leads events\n",
    "df_leads = df_events\\\n",
    "    .withColumn('event_date', to_date(col('event_datetime')))\\\n",
    "    .filter(col('lead_type') != 'Unknown')\\\n",
    "    .filter(col('list_id').isNotNull())\\\n",
    "    .filter(col('list_id') != '0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:09.121Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pdFullDF.groupby('date').agg({'date':'count'})\n",
    "mainCategoriesDict = {1000: 'main 1',\n",
    "                      2000: 'main_2',\n",
    "                      3000: 'main_3'}  \n",
    "\n",
    "categories_dict={1020: 'cat 1',\n",
    "                 1030: 'cat 2',\n",
    "                 2030: 'cat 3'}\n",
    "\n",
    "def createEventsList(x):\n",
    "    events = list()\n",
    "    start = False\n",
    "    end = False\n",
    "    for field in x.index:\n",
    "        if 'objectType_eventType_ElementType_lead_' in field and not end:\n",
    "            if x[field] == 'Page_View__True' and start is False:\n",
    "                # print('PAGE VIEW TRUE FOUND')\n",
    "                start = True\n",
    "            if start:\n",
    "                events.append(x[field])\n",
    "                try:\n",
    "                    if '_Create' in x[field]:\n",
    "                        end = True\n",
    "                except:\n",
    "                    end = True\n",
    "    return events\n",
    "            \n",
    "\n",
    "\n",
    "def listFix(x):\n",
    "    oldList = x\n",
    "    newList = list()\n",
    "    \n",
    "    keyValueFinded = None\n",
    "    \n",
    "    for i in oldList:\n",
    "        if i is None:\n",
    "            keyValueFinded = True\n",
    "        elif '_True' in i:\n",
    "            keyValueFinded = True\n",
    "        if not keyValueFinded:\n",
    "            newList.append(i)\n",
    "        try:\n",
    "            if '_Create' in i:\n",
    "                keyValueFinded = True\n",
    "        except:\n",
    "             keyValueFinded = True\n",
    "    return newList\n",
    "            \n",
    "def findCategorySelected(sortedEventsList):\n",
    "    for event in sortedEventsList[::-1]:\n",
    "        try:\n",
    "            if 'Category Selected' in event:\n",
    "                temp = []\n",
    "                for char in event:\n",
    "                    if char.isnumeric():\n",
    "                        temp.append(char)\n",
    "                return ''.join(temp)\n",
    "        except:\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "def findSubCategorySelected(sortedEventsList):\n",
    "    for event in sortedEventsList[::-1]:\n",
    "        try:\n",
    "            if 'SubCategory Seleted' in event:\n",
    "                temp = []\n",
    "                for char in event:\n",
    "                    if char.isnumeric():\n",
    "                        temp.append(char)\n",
    "                return ''.join(temp)\n",
    "        except:\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "def findLastFormEvent(sortedEventsList):\n",
    "    eventsNames = ['UIElement_Image',\n",
    "                    'UIElement_title',\n",
    "                    'UIElement_description',\n",
    "                    'UIElement_Location Region',\n",
    "                    'UIElement_Seller Name',\n",
    "                    'UIElement_Seller Business Name']\n",
    "    for event in sortedEventsList[::-1]:\n",
    "        for eventName in eventsNames:\n",
    "            try:\n",
    "                if eventName in event:\n",
    "                    return eventName\n",
    "            except:\n",
    "                pass\n",
    "    return 'No Form Events'\n",
    "\n",
    "ad_insert_inmo = ['UIElement_Property Type Section',\n",
    "                    'UIElement_Number of Rooms Section',\n",
    "                    'UIElement_Number of Bathrooms Section',\n",
    "                    'UIElement_Available Equipment Section']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:10.378Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pdFullDF2 = pdFullDF.copy()\n",
    "pdFullDF2['eventsList'] = pdFullDF2.apply((lambda x: createEventsList(x)  ),axis=1)\n",
    "pdFullDF2['lastEvent'] = pdFullDF2['eventsList'].map(lambda x: findLastFormEvent(x) )\n",
    "\n",
    "pdFullDF2['mainCategory'] = pdFullDF2['eventsList'].map(lambda x:findCategorySelected(x) )\n",
    "    \n",
    "pdFullDF2['mainCategoryName'] = pdFullDF2['mainCategory'].map(lambda x: mainCategoriesDict[int(x)] )\n",
    "\n",
    "pdFullDF2['subCategory'] = pdFullDF2['eventsList'].map(lambda x:findSubCategorySelected(x) )\n",
    "\n",
    "pdFullDF2['categoryName'] = pdFullDF2['subCategory'].map(lambda x: categories_dict[int(x)] )\n",
    "\n",
    "pdFullDF2['adInserted'] = pdFullDF2['eventsList'].map(lambda x: 'ClassifiedAd_Create__False' in x ) \n",
    "    \n",
    "print(pdFullDF2.groupby(['date','adInserted']).agg({'adInserted':'count'}).unstack() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:11.222Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_category_integrity(pdFullDF2, ad_insert_inmo):\n",
    "    new_dict = {'date':'', 'environmentId':'', 'mainCategory': '', 'subCategory': '', 'eventsList': [], 'lastEvent': '', \n",
    "               'adInserted': False}\n",
    "    dfAnalysis = pd.DataFrame(columns=new_dict.keys())\n",
    "    new_dict = {'date':'', 'environmentId':'', 'mainCategory': '', 'subCategory': '', 'eventsList': [], 'lastEvent': '', \n",
    "               'adInserted': False}\n",
    "    dfFailed = pd.DataFrame(columns=new_dict.keys())\n",
    "    new_dict = {'date':'', 'environmentId':'', 'mainCategory': '', 'subCategory': '', 'eventsList': [], 'lastEvent': '', \n",
    "               'adInserted': False}\n",
    "    dfInserted = pd.DataFrame(columns=new_dict.keys())\n",
    "    \n",
    "    funnel_ok = 0\n",
    "    funnel_main = 0\n",
    "    funnel_sub = 0\n",
    "    funnel_complete = 0\n",
    "    funnel_fail = 0\n",
    "    \n",
    "    average_events = 0\n",
    "    number_events = 0\n",
    "    \n",
    "    for i, row in pdFullDF2.iterrows():\n",
    "        maincat = row['mainCategory']\n",
    "        subcat = row['subCategory']\n",
    "        eventss = row['eventsList']\n",
    "        # print(eventss)\n",
    "        if len(eventss) > 0:\n",
    "            average_events += len(eventss[1:])\n",
    "            number_events += 1\n",
    "        go = False\n",
    "        for eventt in range(len(eventss)):\n",
    "            eventtt = eventss[eventt]\n",
    "            for eve in ad_insert_inmo:\n",
    "                if eventtt is not None:\n",
    "                    eve1 = eve\n",
    "                    eventtt1 = eventtt\n",
    "                    if '_False' in eventtt:\n",
    "                        eventtt1 = eventtt[0:len(eventtt)-len(\"_False\")]\n",
    "                    elif '_True' in eventtt:\n",
    "                        eventtt1 = eventtt[0:len(eventtt)-len(\"_True\")]\n",
    "                    if '_False' in eve:\n",
    "                        eve1 = eve[0:len(eve)-len(\"_False\")]\n",
    "                    elif '_True' in eve:\n",
    "                        eve1 = eve[0:len(eve)-len(\"_True\")]\n",
    "                    if eve1 in eventtt1:\n",
    "                        go = True\n",
    "                        break\n",
    "        if go:\n",
    "            if len(eventss) > 1:\n",
    "                col_dict_2 = {'date':row['date'], 'environmentId':row['environmentId'], \n",
    "                              'mainCategory': row['mainCategory'], 'subCategory': row['subCategory'], \n",
    "                              'eventsList': row['eventsList'][1:], 'lastEvent': row['lastEvent'],\n",
    "                             'adInserted': row['adInserted']}\n",
    "                dfAnalysis = dfAnalysis.append(col_dict_2, ignore_index=True)\n",
    "                if row['adInserted']:\n",
    "                    dfInserted = dfInserted.append(col_dict_2, ignore_index=True)\n",
    "                else:\n",
    "                    dfFailed = dfFailed.append(col_dict_2, ignore_index=True)\n",
    "            \n",
    "            if maincat == 0 and subcat == 0:\n",
    "                funnel_fail += 1\n",
    "            else:\n",
    "                funnel_ok += 1\n",
    "                if maincat != 0 and subcat != 0:\n",
    "                    funnel_complete +=1\n",
    "                elif maincat == 0 and subcat != 0:\n",
    "                    funnel_sub += 1\n",
    "                elif maincat != 0 and subcat == 0:\n",
    "                    funnel_main += 1\n",
    "    if number_events > 0:\n",
    "        print(\"Average number of events per valid funnel: {}\".format(str(average_events/number_events)))\n",
    "        print(\"Funnel success rate: {} percent\".format(str(100*funnel_ok/(funnel_ok + funnel_fail))))\n",
    "        print(\"Funnel fail rate: {} percent\\n\".format(str(100*funnel_fail/(funnel_ok + funnel_fail))))\n",
    "        print(\"Category and Subcategory complete rate: {} percent\".format(str(100*funnel_complete/funnel_ok)))\n",
    "        print(\"Category complete rate: {} percent\".format(str(100*funnel_main/funnel_ok)))\n",
    "        print(\"Subcategory complete rate: {} percent\".format(str(100*funnel_sub/funnel_ok)))\n",
    "    \n",
    "    return dfAnalysis, dfFailed, dfInserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:11.677Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def distance_to_fail(x, points):\n",
    "    fail_dict = {}\n",
    "    for ele in x:\n",
    "        okk = False\n",
    "        for eve in points:\n",
    "            if ele is not None:\n",
    "                ele1 = ele\n",
    "                eve1 = eve\n",
    "                if '_False' in ele:\n",
    "                    ele1 = ele[0:len(ele)-len(\"_False\")]\n",
    "                elif '_True' in ele:\n",
    "                    ele1 = ele[0:len(ele)-len(\"_True\")]\n",
    "                if '_False' in eve:\n",
    "                    eve1 = eve[0:len(eve)-len(\"_False\")]\n",
    "                elif '_True' in eve:\n",
    "                    eve1 = eve[0:len(eve)-len(\"_True\")]\n",
    "                if eve1 in ele1:\n",
    "                    okk = True\n",
    "        if not okk and ele is not None:\n",
    "            ind1 = x.index(ele)\n",
    "            if ele not in fail_dict.keys():\n",
    "                ele2 = ele\n",
    "                if '_False' in ele:\n",
    "                    ele2 = ele[0:len(ele)-len(\"_False\")]\n",
    "                elif '_True' in ele:\n",
    "                    ele2 = ele[0:len(ele)-len(\"_True\")]\n",
    "                fail_dict[ele2] = 0\n",
    "            for elem in x:\n",
    "                if elem is not None:\n",
    "                    ok = False\n",
    "                    for eve in points:\n",
    "                        elem1 = elem\n",
    "                        eve1 = eve\n",
    "                        if '_False' in elem:\n",
    "                            elem1 = elem[0:len(elem)-len(\"_False\")]\n",
    "                        elif '_True' in elem:\n",
    "                            elem1 = elem[0:len(elem)-len(\"_True\")]\n",
    "                        if '_False' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_False\")]\n",
    "                        elif '_True' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_True\")]\n",
    "                        if eve1 in elem1:\n",
    "                            ok = True\n",
    "                    if ok: \n",
    "                        ind2 = x.index(elem)\n",
    "                        diff = ((ind1 - ind2)**2)**0.5\n",
    "                        ele2 = ele\n",
    "                        if '_False' in ele:\n",
    "                            ele2 = ele[0:len(ele)-len(\"_False\")]\n",
    "                        elif '_True' in ele:\n",
    "                            ele2 = ele[0:len(ele)-len(\"_True\")]\n",
    "                        fail_dict[ele2] = fail_dict[ele2] + diff\n",
    "    return fail_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:12.269Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lastin = 0\n",
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "def full_analysis(dfAnalysis, dfFailed, dfInserted, op=0):\n",
    "    global lastin\n",
    "    if op == 0:\n",
    "        dfAnalysis.to_csv(\"NAA_IMPACT_ALL_FIELDS.csv\")\n",
    "        rows_examine = len(dfAnalysis['eventsList'])\n",
    "        events_dict = {}\n",
    "        keys = []\n",
    "        values = []\n",
    "        agg = 0\n",
    "        for ind in range(rows_examine):\n",
    "            event_list = dfAnalysis['eventsList'][ind]\n",
    "            let = False\n",
    "            for event in event_list:\n",
    "                for eve in ad_insert_inmo:\n",
    "                    if event is not None:\n",
    "                        eve1 = eve\n",
    "                        event1 = event\n",
    "                        if '_False' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_False\")]\n",
    "                        elif '_True' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_True\")]\n",
    "                        if '_False' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_False\")]\n",
    "                        elif '_True' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_True\")]\n",
    "                        if eve1 in event1:\n",
    "                            let = True\n",
    "                            break\n",
    "            if let:\n",
    "                for event in event_list:\n",
    "                    if event is not None:\n",
    "                        if '_False' in event:\n",
    "                            event = event[0:len(event)-len(\"_False\")]\n",
    "                        elif '_True' in event:\n",
    "                            event = event[0:len(event)-len(\"_True\")]\n",
    "                        if event not in events_dict.keys():\n",
    "                            events_dict[event] = 1\n",
    "                        else:\n",
    "                            events_dict[event] = events_dict[event] + 1\n",
    "        tags_resume = pd.DataFrame.from_dict(events_dict, orient='index')\n",
    "        tags_resume.to_csv(\"NAA_TAGS_ADINSERT.csv\")\n",
    "\n",
    "        for i in events_dict.items():\n",
    "            agg += i[1]\n",
    "        for i in events_dict.items():\n",
    "            keys.append(i[0])\n",
    "            values.append(i[1]*(1/agg))\n",
    "        general = pd.DataFrame({\"Tags\": keys, \n",
    "                               \"Frequency %\": values}) \n",
    "        general = general.sort_values('Frequency %', ascending=False)\n",
    "        general = general.iloc[0:25,:]\n",
    "        general['Frequency %'] = general['Frequency %'].apply(lambda x: x*100)\n",
    "        ax0 = sns.barplot(x='Tags', \n",
    "                    y=\"Frequency %\", data=general,  \n",
    "                    order=general.sort_values('Frequency %',ascending = False).Tags)\n",
    "        ax0.set_title('Normalized ad insert general tag frequency %')\n",
    "        ax0.set_xticklabels(ax0.get_xticklabels(),rotation=90)\n",
    "        print(general)\n",
    "        return general\n",
    "    # ------------------------------------------------------------------------------\n",
    "    elif op == 1:\n",
    "        convDF = dfAnalysis.groupby(['date','adInserted']).agg({'adInserted':'count'}).unstack().reset_index()\n",
    "        convDF.columns = ['date','false','true']\n",
    "        convDF['conv'] = convDF.apply((lambda x: x['true']/(x['true']+x['false']) ), axis=1)\n",
    "        print(convDF['true'].mean())\n",
    "        print(convDF['false'].mean())\n",
    "        print(convDF['conv'].mean())\n",
    "    # ------------------------------------------------------------------------------\n",
    "    elif op == 2:\n",
    "        last_tag = {}\n",
    "        keys = []\n",
    "        values = []\n",
    "        \n",
    "        average_events = 0\n",
    "        number_events = 0\n",
    "        agg = 0\n",
    "        for i, row in dfFailed.iterrows():\n",
    "            let = False\n",
    "            for event in row['eventsList']:\n",
    "                for eve in ad_insert_inmo:\n",
    "                    if event is not None:\n",
    "                        eve1 = eve\n",
    "                        event1 = event\n",
    "                        if '_False' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_False\")]\n",
    "                        elif '_True' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_True\")]\n",
    "                        if '_False' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_False\")]\n",
    "                        elif '_True' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_True\")]\n",
    "                        if eve1 in event1:\n",
    "                            let = True\n",
    "                            break\n",
    "            if let:\n",
    "                tag = row['lastEvent']\n",
    "                if tag is not None:\n",
    "                    if '_False' in tag:\n",
    "                        tag = tag[0:len(tag)-len(\"_False\")]\n",
    "                    elif '_True' in tag:\n",
    "                        tag = tag[0:len(tag)-len(\"_True\")]\n",
    "                    if row['lastEvent'] not in last_tag.keys():\n",
    "                        last_tag[row['lastEvent']] = 1\n",
    "                    else:\n",
    "                        last_tag[row['lastEvent']] = last_tag[row['lastEvent']] + 1\n",
    "                    if len(row['eventsList']) > 0:\n",
    "                        average_events += len(row['eventsList'])\n",
    "                        number_events += 1\n",
    "        for i in last_tag.items():\n",
    "            agg += i[1]\n",
    "        for i in last_tag.items():\n",
    "            keys.append(i[0])\n",
    "            values.append(i[1]*(1/agg))\n",
    "        lastin = pd.DataFrame({\"Tags\": keys, \n",
    "                               \"Frequency %\": values}) \n",
    "        lastin = lastin.sort_values('Frequency %', ascending=False)\n",
    "        lastin = lastin.iloc[0:25,:]\n",
    "        lastin['Frequency %'] = lastin['Frequency %'].apply(lambda x: x*100)\n",
    "\n",
    "        ax = sns.barplot(x='Tags', \n",
    "                    y=\"Frequency %\", data=lastin,  \n",
    "                    order=lastin.sort_values('Frequency %',ascending = False).Tags)\n",
    "        ax.set_title('Normalized last Tag before insert fail')\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "        print(\"Normalized average number of events per valid funnel: {}\".format(str(average_events/number_events)))\n",
    "        print(lastin)\n",
    "        return lastin\n",
    "    # ------------------------------------------------------------------------------\n",
    "    elif op == 3:\n",
    "        rows_examine = len(dfFailed['eventsList'])\n",
    "        events_dict = {}\n",
    "        keys = []\n",
    "        values = []\n",
    "        agg = 0\n",
    "        for ind in range(rows_examine):\n",
    "            event_list = dfFailed['eventsList'][ind]\n",
    "            let = False\n",
    "            for event in event_list:\n",
    "                for eve in ad_insert_inmo:\n",
    "                    if event is not None:\n",
    "                        eve1 = eve\n",
    "                        event1 = event\n",
    "                        if '_False' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_False\")]\n",
    "                        elif '_True' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_True\")]\n",
    "                        if '_False' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_False\")]\n",
    "                        elif '_True' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_True\")]\n",
    "                        if eve1 in event1:\n",
    "                            let = True\n",
    "                            break\n",
    "            if let:\n",
    "                for event in event_list:\n",
    "                    if event is not None:\n",
    "                        if '_False' in event:\n",
    "                            event = event[0:len(event)-len(\"_False\")]\n",
    "                        elif '_True' in event:\n",
    "                            event = event[0:len(event)-len(\"_True\")]\n",
    "                        if \"Page_View\" not in event:\n",
    "                            if event not in events_dict.keys():\n",
    "                                events_dict[event] = 1\n",
    "                            else:\n",
    "                                events_dict[event] = events_dict[event] + 1\n",
    "        for i in events_dict.items():\n",
    "            agg += i[1]\n",
    "        for i in events_dict.items():\n",
    "            keys.append(i[0])\n",
    "            values.append(i[1]*(1/agg))\n",
    "        fail = pd.DataFrame({\"Tags\": keys, \n",
    "                               \"Frequency %\": values}) \n",
    "        fail = fail.sort_values('Frequency %', ascending=False)\n",
    "        fail = fail.iloc[0:25,:]\n",
    "        fail['Frequency %'] = fail['Frequency %'].apply(lambda x: x*100)\n",
    "        ax1 = sns.barplot(x='Tags', \n",
    "                    y=\"Frequency %\", data=fail,  \n",
    "                    order=fail.sort_values('Frequency %',ascending = False).Tags)\n",
    "        ax1.set_title('Normalized ad insert tag frequency % of insert fail')\n",
    "        ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n",
    "        print(fail)\n",
    "        return fail\n",
    "    # ------------------------------------------------------------------------------\n",
    "    elif op == 4:\n",
    "        rows_examine = len(dfInserted['eventsList'])\n",
    "        events_dict = {}\n",
    "        keys = []\n",
    "        values = []\n",
    "        average_events = 0\n",
    "        number_events = 0\n",
    "        agg = 0\n",
    "        for ind in range(rows_examine):\n",
    "            event_list = dfInserted['eventsList'][ind]\n",
    "            let = False\n",
    "            for event in event_list:\n",
    "                for eve in ad_insert_inmo:\n",
    "                    if event is not None:\n",
    "                        eve1 = eve\n",
    "                        event1 = event\n",
    "                        if '_False' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_False\")]\n",
    "                        elif '_True' in event:\n",
    "                            event1 = event[0:len(event)-len(\"_True\")]\n",
    "                        if '_False' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_False\")]\n",
    "                        elif '_True' in eve:\n",
    "                            eve1 = eve[0:len(eve)-len(\"_True\")]\n",
    "                        if eve1 in event1:\n",
    "                            let = True\n",
    "                            break\n",
    "            if let:\n",
    "                if len(event_list) > 0:\n",
    "                    average_events += len(event_list)\n",
    "                    number_events += 1\n",
    "                for event in event_list:\n",
    "                    if event is not None:\n",
    "                        if '_False' in event:\n",
    "                            event = event[0:len(event)-len(\"_False\")]\n",
    "                        elif '_True' in event:\n",
    "                            event = event[0:len(event)-len(\"_True\")]\n",
    "                        if \"Page_View\" not in event:\n",
    "                            if event not in events_dict.keys():\n",
    "                                events_dict[event] = 1\n",
    "                            else:\n",
    "                                events_dict[event] = events_dict[event] + 1\n",
    "        for i in events_dict.items():\n",
    "            agg += i[1]\n",
    "        for i in events_dict.items():\n",
    "            keys.append(i[0])\n",
    "            values.append(i[1]*(1/agg))\n",
    "        success = pd.DataFrame({\"Tags\": keys, \n",
    "                               \"Frequency %\": values}) \n",
    "        success = success.sort_values('Frequency %', ascending=False)\n",
    "        success = success.iloc[0:25,:]\n",
    "        success['Frequency %'] = success['Frequency %'].apply(lambda x: x*100)\n",
    "        ax2 = sns.barplot(x='Tags', \n",
    "                    y=\"Frequency %\", data=success,  \n",
    "                    order=success.sort_values('Frequency %',ascending = False).Tags)\n",
    "        ax2.set_title('Normalized ad insert tag frequency % of insert success')\n",
    "        ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n",
    "        print(\"Average number of events per valid funnel: {}\".format(str(average_events/number_events)))\n",
    "        print(success)\n",
    "        return success\n",
    "    # ------------------------------------------------------------------------------\n",
    "    elif op == 5:\n",
    "        failure_points = lastin['Tags'].tolist()\n",
    "        dfFailed['chronicles'] = dfFailed['eventsList'].map(lambda x: distance_to_fail(x, failure_points) )\n",
    "        event_distances = {}\n",
    "        keys = []\n",
    "        values = []\n",
    "        for i, row in dfFailed.iterrows():\n",
    "            events = row['chronicles']\n",
    "            for elem in events.keys():\n",
    "                if elem not in event_distances.keys():\n",
    "                    event_distances[elem] = events[elem]\n",
    "                else:\n",
    "                    event_distances[elem] = event_distances[elem] + events[elem]\n",
    "\n",
    "        for i in event_distances.items():\n",
    "            if i[0] is not None:\n",
    "                keys.append(i[0])\n",
    "                values.append(i[1])\n",
    "        distances = pd.DataFrame({\"Tags\": keys, \n",
    "                               \"Distance\": values}) \n",
    "        distances = distances.sort_values('Distance', ascending=True)\n",
    "        distances = distances.iloc[0:25,:]\n",
    "        ax3 = sns.barplot(x='Tags', \n",
    "                    y=\"Distance\", data=distances,  \n",
    "                    order=distances.sort_values('Distance',ascending = True).Tags)\n",
    "        ax3.set_title('Ad insert tag distances to journey breaks')\n",
    "        ax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n",
    "        for f in failure_points:\n",
    "            print(f)\n",
    "        print(distances)\n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T16:58:39.550Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfHouston2 = dfHouston.toPandas()\n",
    "print(pdFullDF2.environmentId.astype('str'))\n",
    "print(dfHouston2.envIdHouston.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-04T16:27:14.044Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pdFullDF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T16:58:41.944Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfHouston2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T20:25:52.400399",
     "start_time": "2021-03-03T20:24:59.196751Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_people = df_leads.toPandas().copy().merge(pdFullDF2, left_on='environment_id', right_on='environmentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T20:25:52.433756",
     "start_time": "2021-03-03T20:25:52.401777Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T16:58:42.342Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_cases = dfHouston2.copy().merge(pdFullDF2, left_on='envIdHouston', right_on='environmentId')\n",
    "all_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T16:58:43.108Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_cases_2 = all_cases.drop_duplicates(subset=all_cases.copy().drop('eventsList', axis=1).columns.values, keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T16:58:43.863Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(all_cases))\n",
    "print(len(all_cases_2))\n",
    "all_cases_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:30:32.931254",
     "start_time": "2021-02-23T16:29:30.670843Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfAnalysis_A, dfFailed_A, dfInserted_A = check_category_integrity(all_cases_2.loc[all_cases_2['variant'] == 'A'], ad_insert_inmo)\n",
    "print(\"Valid funnels in all A funnels: {} percent\\n\".format(str(100*len(dfAnalysis_A)/len(all_cases_2))) )\n",
    "dfAnalysis_B, dfFailed_B, dfInserted_B = check_category_integrity(all_cases_2.loc[all_cases_2['variant'] == 'B'], ad_insert_inmo)\n",
    "print(\"Valid funnels in all B funnels: {} percent\\n\".format(str(100*len(dfAnalysis_B)/len(all_cases_2))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:30:32.938139",
     "start_time": "2021-02-23T16:30:32.933028Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(dfAnalysis_A), len(dfAnalysis_B))\n",
    "dfAnalysis_B = dfAnalysis_B.iloc[0:len(dfAnalysis_A),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of variant A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:22:26.720895",
     "start_time": "2021-02-23T16:22:26.710354Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 1\n",
    "print('ANALYSIS FAILED A FUNNELS OP {}'.format(str(op)))\n",
    "full_analysis(dfAnalysis_A, dfFailed_A, dfInserted_A, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:26:21.603157",
     "start_time": "2021-02-23T16:26:20.343578Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 2\n",
    "print('ANALYSIS FAILED A FUNNELS OP {}'.format(str(op)))\n",
    "last_A = full_analysis(dfAnalysis_A, dfFailed_A, dfInserted_A, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:26:22.926002",
     "start_time": "2021-02-23T16:26:21.605081Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 3\n",
    "print('ANALYSIS FAILED A FUNNELS OP {}'.format(str(op)))\n",
    "fail_A = full_analysis(dfAnalysis_A, dfFailed_A, dfInserted_A, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:26:46.630006",
     "start_time": "2021-02-23T16:26:22.927610Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 5\n",
    "print('ANALYSIS FAILED A FUNNELS OP {}'.format(str(op)))\n",
    "chronicle_A = full_analysis(dfAnalysis_A, dfFailed_A, dfInserted_A, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:26:48.020674",
     "start_time": "2021-02-23T16:26:46.631635Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 4\n",
    "print('ANALYSIS SUCCESFUL A FUNNELS OP {}'.format(str(op)))\n",
    "success_A = full_analysis(dfAnalysis_A, dfFailed_A, dfInserted_A, op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of variant B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:26:48.033396",
     "start_time": "2021-02-23T16:26:48.022627Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 1\n",
    "print('ANALYSIS FAILED B FUNNELS OP {}'.format(str(op)))\n",
    "full_analysis(dfAnalysis_B, dfFailed_B, dfInserted_B, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:26:49.212218",
     "start_time": "2021-02-23T16:26:48.035124Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 2\n",
    "print('ANALYSIS FAILED B FUNNELS OP {}'.format(str(op)))\n",
    "last_B = full_analysis(dfAnalysis_B, dfFailed_B, dfInserted_B, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:26:50.437636",
     "start_time": "2021-02-23T16:26:49.214335Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 3\n",
    "print('ANALYSIS FAILED B FUNNELS OP {}'.format(str(op)))\n",
    "fail_B = full_analysis(dfAnalysis_B, dfFailed_B, dfInserted_B, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:27:09.734085",
     "start_time": "2021-02-23T16:26:50.439657Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 5\n",
    "print('ANALYSIS FAILED B FUNNELS OP {}'.format(str(op)))\n",
    "chronicle_B = full_analysis(dfAnalysis_B, dfFailed_B, dfInserted_B, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:27:11.301232",
     "start_time": "2021-02-23T16:27:09.736135Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op = 4\n",
    "print('ANALYSIS SUCCESFUL B FUNNELS OP {}'.format(str(op)))\n",
    "success_B = full_analysis(dfAnalysis_B, dfFailed_B, dfInserted_B, op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze differences between variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:27:11.319101",
     "start_time": "2021-02-23T16:27:11.302962Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "last_A.rename(columns = {'Frequency %':'Frequency % A'}, inplace = True) \n",
    "fail_A.rename(columns = {'Frequency %':'Frequency % A'}, inplace = True) \n",
    "success_A.rename(columns = {'Frequency %':'Frequency % A'}, inplace = True) \n",
    "chronicle_A.rename(columns = {'Distance':'Distance A'}, inplace = True) \n",
    "\n",
    "last_B.rename(columns = {'Frequency %':'Frequency % B'}, inplace = True) \n",
    "fail_B.rename(columns = {'Frequency %':'Frequency % B'}, inplace = True) \n",
    "success_B.rename(columns = {'Frequency %':'Frequency % B'}, inplace = True) \n",
    "chronicle_B.rename(columns = {'Distance':'Distance B'}, inplace = True) \n",
    "\n",
    "last_AB = last_A.merge(last_B, how='inner', on='Tags')\n",
    "fail_AB = fail_A.merge(fail_B, how='inner', on='Tags')\n",
    "success_AB = success_A.merge(success_B, how='inner', on='Tags')\n",
    "chronicle_AB = chronicle_A.merge(chronicle_B, how='inner', on='Tags’)\n",
    "\n",
    "last_A = last_A.drop('Frequency % A', axis=1)\n",
    "last_B = last_B.drop('Frequency % B', axis=1)\n",
    "fail_A = fail_A.drop('Frequency % A', axis=1)\n",
    "fail_B = fail_B.drop('Frequency % B', axis=1)\n",
    "success_A = success_A.drop('Frequency % A', axis=1)\n",
    "success_B = success_B.drop('Frequency % B', axis=1)\n",
    "chronicle_A = chronicle_A.drop('Distance A', axis=1)\n",
    "chronicle_B = chronicle_B.drop('Distance B', axis=1)\n",
    "\n",
    "last_not_B = last_A[~last_A.isin(last_B)].dropna()\n",
    "last_not_A = last_B[~last_B.isin(last_A)].dropna()\n",
    "fail_not_B = fail_A[~fail_A.isin(fail_B)].dropna()\n",
    "fail_not_A = fail_B[~fail_B.isin(fail_A)].dropna()\n",
    "success_not_B = success_A[~success_A.isin(success_B)].dropna()\n",
    "success_not_A = success_B[~success_B.isin(success_A)].dropna()\n",
    "chronicle_not_B = chronicle_A[~chronicle_A.isin(chronicle_B)].dropna()\n",
    "chronicle_not_A = chronicle_B[~chronicle_B.isin(chronicle_A)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:27:11.319552",
     "start_time": "2021-02-23T16:26:26.668Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('ad_insert_AB_testing_Houston_filtered.xlsx') as writer:  \n",
    "    last_AB.to_excel(writer, sheet_name='comparison last tag')\n",
    "    fail_AB.to_excel(writer, sheet_name='comparison fail funnel')\n",
    "    success_AB.to_excel(writer, sheet_name='comparison success funnel')\n",
    "    chronicle_AB.to_excel(writer, sheet_name='comparison chronicle')\n",
    "    last_not_B.to_excel(writer, sheet_name='last tag A not B')\n",
    "    last_not_A.to_excel(writer, sheet_name='last tag B not A')\n",
    "    fail_not_B.to_excel(writer, sheet_name='fail funnel A not B')\n",
    "    fail_not_A.to_excel(writer, sheet_name='fail funnel B not A')\n",
    "    success_not_B.to_excel(writer, sheet_name='success funnel A not B')\n",
    "    success_not_A.to_excel(writer, sheet_name='success funnel B not A')\n",
    "    chronicle_not_B.to_excel(writer, sheet_name='chronicle A not B')\n",
    "    chronicle_not_A.to_excel(writer, sheet_name='chronicle B not A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cat",
   "language": "python",
   "name": "cat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
